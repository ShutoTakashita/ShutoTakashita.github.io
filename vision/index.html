<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Vision — Plausible Embodiment</title>
    <link rel="stylesheet"
        href="https://fonts.googleapis.com/css2?family=Big+Shoulders+Display:wght@700&family=Roboto:wght@400;700&display=swap" />
    <style>
        body {
            font-family: 'Roboto', Arial, sans-serif;
            background-color: #111118;
            color: #e0e0e8;
            text-align: center;
            padding: 50px 0;
            margin: 0;
            line-height: 1.7;
            -webkit-font-smoothing: antialiased;
        }

        .logo {
            display: block;
            text-align: left;
            padding-left: 20px;
            margin-bottom: 10px;
        }

        .logo img {
            width: 50px;
        }

        header {
            margin-bottom: 20px;
        }

        h1 {
            margin-top: 0;
            color: #ffffff;
            letter-spacing: 0.02em;
        }

        h2 {
            margin-top: 32px;
            margin-left: 10px;
            color: #00BCD4;
            border-bottom: 1px solid #2a2a38;
            padding-bottom: 6px;
        }

        h3 {
            color: #c8c8d4;
        }

        ul {
            list-style: none;
            padding: 0;
            margin: 20px 0;
        }

        li {
            margin-bottom: 10px;
            margin-left: 20px;
            margin-right: 20px;
            color: #c8c8d4;
        }

        .detail-section {
            text-align: left;
            margin: 0 auto;
            max-width: 960px;
            padding: 0 20px;
        }

        .detail-section p {
            color: #c8c8d4;
        }

        .lang-toggle {
            margin-top: 10px;
        }

        .lang-toggle button {
            background: none;
            border: 1px solid #00BCD4;
            color: #00BCD4;
            padding: 6px 14px;
            margin: 0 4px;
            cursor: pointer;
            border-radius: 4px;
            font-size: 0.9em;
            transition: all 0.2s ease;
        }

        .lang-toggle button:hover {
            background: rgba(0, 188, 212, 0.15);
        }

        .lang-toggle button.active {
            background: #00BCD4;
            color: #111118;
        }

        .section-img {
            display: block;
            width: 100%;
            max-width: 700px;
            margin: 24px auto;
            border-radius: 8px;
        }

        .section-img-small {
            display: block;
            width: 100%;
            max-width: 500px;
            margin: 24px auto;
            border-radius: 8px;
        }

        blockquote {
            border-left: 3px solid #00BCD4;
            padding-left: 16px;
            margin: 28px 0;
            font-style: italic;
            color: #9a9ab0;
        }

        a {
            color: #e0e0e8;
            text-decoration: none;
            transition: color 0.2s ease;
        }

        a:hover {
            color: #00BCD4;
        }

        strong {
            color: #e0e0e8;
        }

        @media (min-width: 768px) {
            img[src$=".png"] {
                margin: 24px auto;
            }
        }
    </style>
</head>

<body>
    <header>
        <div class="logo"><a href="http://shike-xr.com"><img src="logo_white.png" alt="Shike XR Logo" /></a></div>
        <h1>Vision</h1>
        <div class="lang-toggle">
            <button id="btn-jp" class="active" onclick="setLang('jp')">日本語</button>
            <button id="btn-en" onclick="setLang('en')">English</button>
        </div>
    </header>

    <!-- Japanese content -->
    <div id="content-jp">
        <div class="detail-section">
            <h2>Plausible Embodiment</h2>
            <h3>「もしこの身体を持っていたら、きっとこう感じ、こう動くだろう」</h3>

            <p>バーチャルリアリティの技術は、ヒトの感覚運動の入出力をシミュレートし、仮想環境とのインタラクションを実質的に再現することを目指してきました。ユーザーの運動はセンサを通じてトラッキングされ、それがアバターの身体において実行され、アバターが受け取るべき触覚や視覚がディスプレイを通じてユーザーに伝えられます。</p>

            <p>これはユーザーがヒト型のアバターを使う場合には上手く成立します。しかし、<strong>非ヒト型のアバターの場合は破綻します</strong>。例えば、我々ヒトはタコの身体に生きたことがないため、タコの身体がどのように働くべきか、どのように感じるべきかを知りません。蛇はピット器官で熱を感じ取りますが、蛇アバターのユーザーにはそれを視覚として与えるべきでしょうか、それとも熱として与えるべきでしょうか？　非ヒト型身体の「本物の」感覚運動は我々人間が知る手段がなく、再現すべき正解が存在しないのです。</p>

            <img src="Teaser.png" alt="Realism Paradigm vs Non-Human Avatars" class="section-img">

            <p>よって、非ヒト型アバターを身体として扱うためには、現実の感覚運動の再現ではなく、<strong>ヒトと非ヒト間で操作と感覚を調停するデザイン</strong>が必要になります。</p>

            <h2>フレームワーク：期待に基づくデザイン</h2>

            <p>私は、このデザインの原理として<strong>Plausible Embodiment</strong>を提案しています。Plausible Embodimentとは、非ヒト型アバター身体における操作と感覚の構成が、ユーザーによってその身体にふさわしいものとして受け入れられ、そのアバターを自分の身体として使う際に頼りにできる状態を指します。簡潔に言えば、<strong>「もしこの身体を持っていたら、きっとこう感じ、こう動くだろう」</strong>と感じられる体験を設計することが目標です。</p>

            <p>このフレームワークでは、ユーザーがアバター身体に対して抱く種々の<strong>期待</strong>――身体認知、ステレオタイプ、知覚されるアフォーダンス――をデザインリソースとして活用します。例えば、尻尾の位置感覚を伝えるには、振動や視覚呈示よりも、腰付近への皮膚伸長フィードバックの方が深い没入感を生み出します。この差を生むのは「その身体ではその感覚はこう感じられるはずだ」というユーザーの期待です。</p>

            <img src="Framework.png" alt="Plausible Embodiment Framework" class="section-img-small">

            <h2>3つの研究</h2>

            <p>これまでに、操作・感覚・社会的実践の3つのレイヤーから、Plausible Embodimentに関するデザイン上の知見を得てきました。</p>

            <h3>Plausible Control: Embodied Tentacle</h3>
            <p>タコ型の仮想腕に対する異なるマッピングがユーザー体験にどのように影響するかを調査しました。12セグメントのタコ型仮想腕を構築し、右手の12の指関節に一対一でマッピングする4種類の条件を比較した結果、<strong>ユーザーのアバター身体に対する認知的解釈に沿ったマッピング</strong>がもっとも理解しやすく、もっともらしい操作体験を生むことが明らかになりました。例えば、小指を「手の先端」と認識するユーザーにとっては、小指がタコ腕の先端に対応するマッピングがより直感的でした。</p>

            <img src="teaser2.png" alt="Embodied Tentacle" class="section-img">

            <h3>Plausible Sensation: Imaginary Joint</h3>
            <p>ユーザーの生来の身体と仮想の身体拡張（尻尾など）の境界を「仮想的な関節」として再定義し、その関節周囲の皮膚伸長によって固有受容感覚フィードバックを与える手法を提案しました。21名の実験で皮膚伸長と振動を比較した結果、皮膚伸長はより正確な知覚と高い身体所有感をもたらしました。参加者からは<strong>「振動はただの信号だが、皮膚伸長は自分の身体の一部のように感じる」「もし尻尾があったら、まさにこう感じるだろう」</strong>というコメントが得られ、皮膚伸長がPlausible Embodimentをより効果的に支援することが示されました。</p>

            <img src="ImaginaryJoint.png" alt="Imaginary Joint" class="section-img-small">

            <h3>Practices of Plausibility: Escape From Human</h3>
            <p>日本のVRChatコミュニティにおける非ヒト型アバターユーザーへのインタビュー研究を行いました。ケンタウロス、ラミア、多腕生物、動物型アバターなどを用いるユーザーは、単にアバター身体を感じたいだけではなく、<strong>その身体らしい方法で感じ、操作することを望んでいる</strong>ことが明らかになりました。また、現実の身体的コミュニケーションをそのまま再現できない非ヒト型身体においては、身体形態に対するユーザー間の共通理解に基づいて<strong>新たな身体的コミュニケーション</strong>が自発的に生み出されていることも明らかになりました。</p>

            <img src="avatars2.png" alt="Non-Human Avatars in Social VR" class="section-img">

            <h2>今後の展望</h2>

            <p>今後は、操作・感覚・コミュニケーションそれぞれにおけるplausibilityの要件と多様性をさらに精緻化し、追加のレイヤーも探求していきます。また、ユーザーの事前期待を測定・形成する方法についても調査を進めていきます。キャラクターの物語や特性を事前に確立することで、ユーザーに新たな能力を「インストール」し、それらの能力がどのように感じられ、機能するかへの期待を形成することができるかもしれません。</p>

            <blockquote>
                Plausible Embodimentは、再現すべきゴールドスタンダードが存在しない非ヒト型アバター体験において、それでもユーザーの期待を基に、尤もらしい体験を作り出すためのフレームワークです。この研究を通じて、私は「非人間的存在に宿る人間の能力」の限界を探求し、拡張することを目指します。
            </blockquote>

            <p>さらに、ヒト-非ヒトで環世界が異なることに関連して、ヒト同士においても同じ外部刺激への知覚の仕方は多様です。例えば、AさんとBさんは同じ「赤色」を経験しているとは限りません。その多様さを理解し、個々人間の差を技術で調停していくことにも、この研究を役立てたく思います。</p>

            <p style="text-align:center;margin-top:40px;">
                これまでの内容にご興味のある方はお気軽にご連絡ください。共同研究のお誘い・インターンのご応募を歓迎しています。
            </p>
            <p style="text-align:center;font-weight:bold;">
                東京大学　稲見研究室　博士二年　高下修聡　<br>
                <a href="https://twitter.com/shike_cosmicXR" target="_blank">@shike_cosmicXR</a><br>
                <a href="mailto:shuto.takashita@star.rcast.u-tokyo.ac.jp">shuto.takashita@star.rcast.u-tokyo.ac.jp</a>
            </p>
        </div>
    </div>

    <!-- English Content -->
    <div id="content-en" style="display:none">
        <div class="detail-section">
            <h2>Plausible Embodiment</h2>
            <h3>"If I had this body, it would feel and work like this."</h3>

            <p>Virtual reality technology has aimed to simulate human sensorimotor input and output in order to reproduce interactions with virtual environments. User movements are tracked through sensors, executed by an avatar body, and the tactile and visual feedback the avatar should receive is conveyed back to the user through displays.</p>

            <p>This approach works well when the user inhabits a humanoid avatar. However, <strong>it breaks down for non-human avatars</strong>. Humans have never lived with the body of an octopus, and therefore lack knowledge of how such a body should function or feel. Snakes sense heat through pit organs, but should a snake avatar present this to the user as visual information or thermal feedback? The authentic sensorimotor experience of non-human bodies is fundamentally unknowable to us, and therefore there is no correct reference to reproduce.</p>

            <img src="Teaser.png" alt="Realism Paradigm vs Non-Human Avatars" class="section-img">

            <p>Therefore, to treat a non-human avatar as one's own body, we must move away from reproducing real sensorimotor experience and instead <strong>design interactions that mediate action and sensation between human and non-human bodies</strong>.</p>

            <h2>Framework: Expectation-Guided Design</h2>

            <p>I propose <strong>Plausible Embodiment</strong> as a design principle for non-human avatar experiences. Plausible Embodiment refers to a state in which a configuration of control and sensation within a non-human avatar body, differing in form from the human body, is accepted by the user as appropriate for that body and can be relied upon to use the avatar as one's own body. In short, the goal is to design experiences that lead users to the belief that <strong>"if I had this body, it would feel and work like this."</strong></p>

            <p>This framework leverages users' <strong>expectations</strong> toward avatar bodies — body cognition, stereotypes, and perceived affordances — as design resources. For example, when conveying the positional sensation of a tail, skin stretch feedback around the hips produces a deeper sense of immersion than vibration or purely visual cues. What creates this difference is the user's expectation of how such a sensation would be felt in that body.</p>

            <img src="Framework.png" alt="Plausible Embodiment Framework" class="section-img-small">

            <h2>Three Studies</h2>

            <p>Through three studies on control, sensation, and social practice, I have derived design insights on Plausible Embodiment across multiple layers of non-human avatar embodiment.</p>

            <h3>Plausible Control: Embodied Tentacle</h3>
            <p>This study investigated how different control mappings for an octopus-like virtual arm affect user experience. A 12-segment virtual arm was mapped one-to-one onto the 12 finger joints of the user's right hand across four conditions. Results revealed that <strong>mappings aligned with users' cognitive interpretations of the avatar body</strong> produced the most understandable and plausibly embodied control experience. For example, participants who perceived the little finger as the "tip" of the hand found mappings where the little finger controlled the tentacle tip more intuitive.</p>

            <img src="teaser2.png" alt="Embodied Tentacle" class="section-img">

            <h3>Plausible Sensation: Imaginary Joint</h3>
            <p>This study proposed reframing the boundary between a user's innate body and a virtual extension (such as a tail) as an "Imaginary Joint," delivering proprioceptive feedback through localized skin stretch. In a study with 21 participants comparing skin stretch against vibrotactile feedback, skin stretch produced more accurate perception and higher body ownership. Participants commented that <strong>"vibration just feels like a signal, whereas skin stretch feels like part of my body"</strong> and <strong>"if I had a tail, I imagine it would feel just like this,"</strong> indicating that skin stretch supports Plausible Embodiment at the level of sensation more effectively than vibration.</p>

            <img src="ImaginaryJoint.png" alt="Imaginary Joint" class="section-img-small">

            <h3>Practices of Plausibility: Escape From Human</h3>
            <p>An interview study was conducted with non-human avatar users in Japanese VRChat communities. Users of centaurs, lamias, multi-armed creatures, and animal-form avatars revealed that they do not merely want to feel their avatar bodies — they desire to <strong>perceive and control them in ways that feel appropriate to those specific bodies</strong>. Furthermore, since existing communicative conventions cannot be directly applied to non-human forms, <strong>new forms of bodily communication</strong> are spontaneously emerging based on shared understandings of how those bodies should behave.</p>

            <img src="avatars2.png" alt="Non-Human Avatars in Social VR" class="section-img">

            <h2>Future Directions</h2>

            <p>Going forward, I aim to further refine the requirements and varieties of plausibility across operation, sensation, and communication, and to explore additional layers. I also plan to investigate methods for measuring and shaping users' prior expectations as a means of designing more plausible experiences. By pre-establishing narratives or characteristics of a character, it may become possible to "install" new capabilities in users by shaping how those abilities are expected to feel and function.</p>

            <blockquote>
                The Plausible Embodiment framework is a design principle for creating believable experiences in non-human avatar embodiment, where no gold standard exists. Through this research, I aim to explore and extend the limits of human capabilities as they inhabit non-human entities.
            </blockquote>

            <p>Furthermore, related to the fact that humans and non-humans inhabit different Umwelten, the way individuals perceive the same external stimuli varies even among humans. For example, person A and person B may not experience the same "red." I hope this research can also contribute to understanding such perceptual diversity and mediating individual differences through technology.</p>

            <p style="text-align:center;margin-top:40px;">
                If this vision resonates with you, feel free to reach out. I welcome collaborations and internships.
            </p>
            <p style="text-align:center;font-weight:bold;">
                Shuto Takashita, PhD Year 2, Inami Lab, The University of Tokyo<br />
                <a href="https://twitter.com/shike_cosmicXR" target="_blank">@shike_cosmicXR</a><br />
                <a href="mailto:shuto.takashita@star.rcast.u-tokyo.ac.jp">shuto.takashita@star.rcast.u-tokyo.ac.jp</a>
            </p>
        </div>
    </div>

    <script>
        function setLang(lang) {
            document.getElementById('content-jp').style.display = (lang === 'jp') ? 'block' : 'none';
            document.getElementById('content-en').style.display = (lang === 'en') ? 'block' : 'none';
            document.getElementById('btn-jp').classList.toggle('active', lang === 'jp');
            document.getElementById('btn-en').classList.toggle('active', lang === 'en');
            document.documentElement.lang = lang;
        }
    </script>
</body>

</html>